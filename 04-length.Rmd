# Length data {#length}

## Data processing

### Load needed data

* Load the DATRAS raw data previously imported
* Read in table containing latin name, code type (T or W) and the corresponding code:


### Tidy up the length data

Processing:

* Only distinct records (they are all distinct)
* Filter out data were species code, length-code and length-class are undefined
* Set lengths to millimeter. In the raw records:
    - If **lngtcode** is "1" then the **lngtclass** is in centimeters
    - If **lngtcode** is "." or "0" then the **lngclass** is in millimeters
* Standardise the **haul numbers at length**. In the raw data:
    - If **datatype** in the station table is "C" then **hlnoatlngt** has been standardized to 60 minutes haul
    - If **datatype** in the station table is "R" then **hlnoatlngt** has not been standardized to 60 minutes haul
* Get the latin species name from the `sp`-table
* Select only variable that are needed in further processing
    
```{r}
# read in species code
sp <- read_csv("data-raw/SPCODE.csv")
glimpse(sp)

LE <-
  NSIBTS$le %>%
  distinct() %>%
  filter(!is.na(speccode), !is.na(lngtclass), !is.na(lngtcode)) %>%
  # EINAR - not sure if this is right, done here to test if any difference
  #         (did though not help with respect to discrepancy here below)
  filter(specval == 1) %>% 
  unite(id, year, quarter, ship, gear, haulno) %>%
  # only stations that are in the station table (north sea area)
  filter(id %in% ST$id) %>% 
  # length class to mm
  mutate(length = ifelse(lngtcode %in% c("1"), lngtclass * 10, lngtclass),
         hlnoatlngt = hlnoatlngt * subfactor) %>% 
  # get the data type and hauldur
  left_join(ST %>% select(id, datatype, hauldur)) %>% 
  # catch per hour
  mutate(n = ifelse(datatype == "R",
                    hlnoatlngt * 60 / hauldur,
                    hlnoatlngt)) %>% 
  # join with latin name
  left_join(sp) %>%
  # select only needed columns
  select(id, latin, sex, length, n)
```

## CPUE by length class

### By each tow

Since we are here ignoring sex in the analysis, we tally up the data by length class. This also tallies up the subfactor data:

```{r}
# tally up by sex
le <-
  LE %>%
  group_by(id, latin, length) %>%
  summarise(n = sum(n)) %>%
  ungroup()
```


Limit the species in the analysis to "common" species (this step is not really necessary):
```{r}
common <- c("Clupea harengus", "Sprattus sprattus", "Gadus morhua",
            "Melanogrammus aeglefinus", "Merlangius merlangus", "Pollachius virens",
            "Trisopterus esmarkii", "Scomber scombrus", "Pleuronectes platessa")
le <-
  le %>%
  # only common species
  filter(latin %in% common)
glimpse(le)
```

#### Merging the station table and the length table

```{r}
st <- 
  # Fill "a station table" for each species:
  expand.grid(id = unique(ST$id),
              latin = common,
              stringsAsFactors = FALSE) %>% 
  tbl_df()
# stations with "missing species"
# "return all rows from st where there are not matching values in length, keeping just columns from st."
x <- 
  anti_join(st, le %>% select(id, latin) %>% distinct()) %>% 
  # fill with remainder of variables
  left_join(ST) %>% 
  # create a zero record
  mutate(length = 0,
         n = 0)
cpue <-
  ST %>%
  left_join(le) %>% 
  # add the zero stations
  bind_rows(x) %>% 
  filter(!is.na(latin),
         year < 2017)
```

### Some simple summaries

```{r}
cpue %>% 
  group_by(id, latin) %>% 
  summarise(n = sum(n)) %>%
  separate(id, c("year", "quarter", "ship", "gear", "haulno"), convert = TRUE) %>%
  filter(quarter %in% c(1, 3)) %>% 
  mutate(year = year + quarter/4) %>% 
  ggplot(aes(year, n, colour = factor(quarter))) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.1) +
  expand_limits(y = 0) +
  facet_wrap(~ latin, scale = "free_y") +
  scale_color_brewer(palette = "Set1") +
  labs(x = NULL, y = NULL,
       colour = "Quarter",
       title = "Annual abundance",
       subtitle = "Bootstrap mean and confidence interval of individual tows") +
  scale_x_continuous(breaks = seq(2005,2015,5))
```


```{r}
d <-
  cpue %>%
  group_by(year, quarter, latin, length) %>% 
  summarise(n = sum(n)/1e3) %>% 
  mutate(length = length/10) %>% 
  ungroup()
d %>%
    filter(latin == "Melanogrammus aeglefinus",
         quarter == 1) %>% 
  ggplot(aes(length, n)) +
  geom_line() +
  facet_grid(year ~ .)
d %>%
    filter(latin == "Gadus morhua",
         quarter == 1) %>% 
  ggplot(aes(length, n)) +
  geom_line() +
  facet_grid(year ~ .)
d %>%
    filter(latin == "Pleuronectes platessa",
         quarter == 1) %>% 
  ggplot(aes(length, n)) +
  geom_line() +
  facet_grid(year ~ .)
```

__Mean by subarea__:
```{r}
le_cm <-
  le %>% 
  mutate(length = length/10)
gr <- 
  expand.grid(id = ST$id,
              length = 0:200,
              stringsAsFactors = FALSE)
d <- 
  gr %>% 
  left_join(ST %>% select(id, area, subarea)) %>% 
  left_join(le_cm %>% filter(latin == "Gadus morhua")) %>% 
  mutate(n = ifelse(is.na(n), 0, n)) %>% 
  select(-latin) %>% 
  separate(id, c("year", "quarter", "ship", "gear", "haulno"), convert = TRUE) %>% 
  group_by(year, quarter, area, subarea, length) %>% 
  summarise(n = mean(n)) %>% 
  ungroup()
```

```{r, eval = FALSE, echo = FALSE}
# a comparions with datras product
d2 <- read_csv("data-raw/CPUE per length per subarea_2017-06-21 13_15_57.csv")
colnames(d2) <- tolower(colnames(d2))
d2 <-
  d2 %>% 
  filter(species == "Gadus morhua") %>% 
  select(year, quarter, subarea, length = lngtclass, n.datras = cpue_number_per_hour) %>% 
  mutate(length = length/10)
d3 <-
  d %>% 
  left_join(d3) %>% 
  mutate(n.datras = ifelse(is.na(n.datras), 0, n.datras))
d3 %>% 
  mutate(n = round(n, 3)) %>% 
  filter(n != n.datras) %>% 
  ggplot(aes(n, n.datras)) +
  geom_point()
d3 %>% 
  mutate(n = round(n, 3)) %>% 
  filter(n != n.datras) %>% 
  ggplot(aes(n - n.datras)) +
  geom_histogram()
```

__Mean by area__:

```{r}
#d.stored <- d
d <- 
  d %>% 
  group_by(year, quarter, area, length) %>% 
  summarise(n = mean(n)) %>% 
  ungroup()
```

```{r}
d %>% 
  filter(year == 2017,
         quarter == 1, 
         length <= 110) %>% 
  mutate(area = as.integer(area)) %>% 
  ggplot(aes(length, n, colour = factor(area))) +
  geom_line(lwd=1) +
  scale_colour_brewer(palette = "Set3")
```

```{r}
d %>% 
  group_by(year, quarter, area) %>% 
  summarise(n = sum(n)) %>%
  ungroup() %>% 
  filter(quarter %in% c(1, 3)) %>% 
  mutate(area = as.integer(area),
         year = year + quarter/4) %>% 
  ggplot(aes(year, n, colour = factor(quarter))) +
  geom_point() +
  geom_line() +
  expand_limits(y = 0) +
  facet_wrap(~ area, scale = "free_y") +
  scale_color_brewer(palette = "Set1") +
  labs(x = NULL, y = NULL,
       colour = "Quarter",
       title = "Annual mean abundance",
       subtitle = "Mean based on cpue by area") +
  scale_x_continuous(breaks = seq(2005,2015,5))


d %>% 
  group_by(year, quarter, area) %>% 
  # sum all length data
  summarise(n = sum(n)) %>%
  ungroup() %>% 
  filter(quarter %in% c(1, 3)) %>% 
  mutate(year = year + quarter/4) %>% 
  ggplot(aes(year, n, colour = factor(quarter))) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.1) +
  expand_limits(y = 0) +
  scale_color_brewer(palette = "Set1") +
  labs(x = NULL, y = NULL,
       colour = "Quarter",
       title = "Annual abundance",
       subtitle = "Bootstrap mean and confidence interval of data by area") +
  scale_x_continuous(breaks = seq(2005,2015,5))
```

```{r echo = FALSE, eval = FALSE}
# comparison with datras product
d2 <- read_csv("data-raw/CPUE per length per area_2017-06-21 13_17_49.csv")
colnames(d2) <- tolower(colnames(d2))
d2 <-
  d2 %>% 
  filter(species == "Gadus morhua") %>% 
  select(year, quarter, area, length = lngtclass, n.datras = cpue_number_per_hour) %>% 
  mutate(length = length/10)
d3 <-
  d %>% 
  left_join(d3) %>% 
  mutate(n.datras = ifelse(is.na(n.datras), 0, n.datras))
d3 %>% 
  mutate(n = round(n, 3)) %>% 
  filter(n != n.datras) %>% 
  ggplot(aes(n, n.datras)) +
  geom_point()
d3 %>% 
  mutate(n = round(n, 3)) %>% 
  filter(n != n.datras) %>% 
  ggplot(aes(n - n.datras)) +
  geom_histogram()
```


## Comparison Datras service product

```{r}
cpue.datras.service.product <-
  read_csv("~/prj2/bookdown/datrasdoodle/data-raw/CPUE per length per haul_2017-06-21 09_36_43.csv", na = "-9")
colnames(cpue.datras.service.product) <- tolower(colnames(cpue.datras.service.product))
#cpue.datras.service.product %>% filter(ship == "58G2") %>% select(survey:haulno, subarea)
cpue.datras.service.product <-
  cpue.datras.service.product %>%
  unite(id, year, quarter, ship, gear, haulno, remove = FALSE) %>% 
  select(id, latin = species, length = lngtclass, cpue.dsp = cpue_number_per_hour)

diff <-
  cpue %>%
  filter(year < 2017) %>% 
  select(id, latin, length, cpue.tidy = n) %>% 
  full_join(cpue.datras.service.product) %>%
  mutate(diff = !near(cpue.dsp, cpue.tidy, tol = 1e-4),
         txt = ifelse(!diff, "Same",
                      ifelse(diff, "Difference", "One of the value is NA")))
diff %>% 
  group_by(txt) %>% 
  summarise(n.records = n()) %>% 
  knitr::kable()
```

We have 516950 records that are OK. We have 1668 values that are "NA" meaning that either of the cpue or both were missing. And then 953 records that are different.

Lets see what difference there is in the overview:

```{r}
cpue.datras.service.product <-
  read_csv("~/prj2/bookdown/datrasdoodle/data-raw/CPUE per length per haul_2017-06-21 09_36_43.csv", na = "-9")
colnames(cpue.datras.service.product) <- tolower(colnames(cpue.datras.service.product))
#cpue.datras.service.product %>% filter(ship == "58G2") %>% select(survey:haulno, subarea)
cpue.datras.service.product <-
  cpue.datras.service.product %>%
  unite(id, year, quarter, ship, gear, haulno, remove = FALSE) %>% 
  select(id, year, quarter, subarea, latin = species, length = lngtclass, n = cpue_number_per_hour) %>% 
  mutate(source = "datras")
cpue2 <- 
  cpue %>% 
  filter(!is.na(latin)) %>% 
  select(id, year, quarter, subarea, latin, length, n) %>% 
  mutate(source = "tidy")
d <-
  bind_rows(cpue.datras.service.product, cpue2) %>% 
  group_by(source, year, quarter, latin, subarea) %>% 
  summarise(n = mean(n)) %>% 
  group_by(year, quarter, source, latin) %>% 
  summarise(n = mean(n))
d %>% 
  filter(quarter %in% c(1, 3)) %>% 
  mutate(split = paste(latin, quarter)) %>% 
  ggplot(aes(year, n, colour = source)) +
  geom_point() +
  geom_line() +
  facet_wrap(~ split, scale = "free_y") +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = c(0.8, 0.1))
```

So overall, the difference is minor.

**List of records that are different**:

```{r}
diff %>% filter(is.na(diff) | diff) %>% knitr::kable()
```


## Field names

* **StNo**: National coding system, not defined by ICES
* **HaulNo**: Sequential numbering of hauls during cruise. In CA-records: HaulNo = -9 for Area-based ALK HaulNo <> -9 and > 0 for Haul-based ALK
* **DataType**:
    - -9: Invalid haul
    - C: Data calculated as CPUE (number per hour)
    - R: Data by haul
    - S: Subsample data
* **SpecCodeType**:
    - N: NODC code
    - T: TSN code
    - W: WoRMS ApiaID code
* **LngtCode**:
    - .:	1 mm length class, reporting units: mm
    - 0:	0.5 cm length class, reporting units: mm
    - 1:	1 cm length class, reporting units: cm
* **CatIdentifier**: Category for subsampling for species, length, weight, and sex. If **DataType** is C, **CatIdentifier** is always 1. For further description and examples of use look up the manual.
* **SubFactor**: Sub-sampling factor. If 1/6 of the catch was measured, report 6. If **DataType** is:
    - C: it should be reported as 1. 
    - S: it is always >1.
    - R: the SubFactor is = 1 or >1 for different species depending on whether they were subsampled.
