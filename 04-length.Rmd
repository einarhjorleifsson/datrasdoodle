# Length data {#length}

## Preamble
___

Load libraries and data:

```{r, warning = FALSE, message = FALSE}
library(tidyverse)
library(lubridate)
library(tidyices)
library(ggridges)
```

```{r}
hh <- read_rds("data/ns-ibts_hh.rds")
hl <- read_rds("data/ns-ibts_hl.rds")
```

## Catch per haul
___

### Abundance (counts)

Since in the tidying process all length data counts were standardized to 60 minutes haul time it is relatively straight forward to calculate the standardized abundance per 60 minute haul. Lets do this for some species of choice:

```{r}
Latin <- "Pleuronectes platessa"
by.haul.positive <- 
  hl %>% 
  select(-sex) %>% 
  filter(latin == Latin) %>% 
  # NOTE: I am not sure if the next step is kosher
  #       Basically droping rows where length and/or n is NA
  #       Check with the DATRAS experts
  drop_na() %>% 
  group_by(id) %>% 
  summarise(n = sum(n))
```

In the code above we have basically collapsed the abundance by length to abundance by haul. The number of records in the by.haul dataframe are `r nrow(by.haul.positive)` while the number of hauls in the haul dataframe are `r nrow(hh)`. The difference are hauls where no *`r Latin`* was caught.

In order to include the stations with zero catch we:

* Take the haul data and do a left join with the length data which have some catch recorded. A demonstration of the join-function family is provided using some simple data in [On joins](#joins).
* This results in the zero stations having NA in the n variable. Hence the mutate in combination with replace_na comes to the rescue, setting a value of zero as count for stations where no fish was caught otherwise retain the count value.

```{r, message = FALSE}
by.haul <-
  hh %>% 
  select(id, year, quarter, haulval) %>% 
  left_join(by.haul.positive) %>%
  mutate(n = replace_na(n, 0))
```

We now have a dataframe that looks like this:
```{r}
glimpse(by.haul)
```

A quick count:
```{r}
table(by.haul$haulval, by.haul$n == 0, useNA = "ifany")
```

reveals that we have `r by.haul %>% filter(haulval == "V", n > 0) %>% nrow()` valid hauls with `r Latin` and `r by.haul %>% filter(haulval == "V", n == 0) %>% nrow()` valid hauls where no `r Latin` was caught.

Since we are here we may as well look at the temporal trend in the mean abundance using only the valid hauls:

```{r}
by.haul %>% 
  filter(haulval == "V") %>% 
  group_by(year, quarter) %>% 
  summarise(m = mean(n)) %>% 
  ungroup() %>% 
  mutate(year = year + 0.25 * quarter - 0.125) %>% 
  ggplot(aes(year, m, colour = factor(quarter), group = quarter)) +
  geom_point() +
  geom_line() +
  scale_color_brewer(palette = "Set1") +
  labs(x = NULL, y = NULL,
       colour = "Quarter",
       title = paste0(Latin, ": Mean number per 1 hour haul"))
```

Now the trend in the abundance, particularly in the earlier part of the time-series may be confounded with the survey coverage and sampling design over time (TODO: More on that later).

Using the mean may not be appropriate here, given the general distribution of abundance by haul one observes in groundfish surveys:

```{r, message = FALSE}
by.haul %>% 
  filter(haulval == "V") %>% 
  # put the values above the 99%th percentile to 99%th percentile
  #  just for display purpose
  mutate(n = ifelse(n > quantile(n, 0.99), quantile(n, 0.99), n)) %>% 
  ggplot(aes(n)) +
  geom_histogram() +
  labs(x = "Abundance per haul",
       y = "Number of stations")
```

Here most hauls are with relatively small or zero catches with occasional hauls with very large catches resulting in a highly negatively scewed distribution. The ggplot2 package has a very nice summary statistics (bootstrap mean and standard error) that comes to the rescue:

```{r}
by.haul %>% 
  filter(haulval == "V") %>% 
  mutate(year = year + 0.25 * quarter - 0.125) %>% 
  ggplot(aes(year, n, colour = factor(quarter))) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.1) +
  expand_limits(y = 0) +
  scale_color_brewer(palette = "Set1") +
  labs(x = NULL, y = NULL,
       colour = "Quarter",
       title = paste("Mean number of", Latin, "per 1 hour haul"),
       subtitle = "Bootstrap mean and one standard error")
```

### Biomass (weight)

If one is interested in obtaining biomass trend the above code can easily be amendment (actually expanded), using some isometric length-weight parameters as a rough guess for the weight as a function of length (we will obtain more reasonable parameters based on some length-weight data in chapter XXX). We start from scratch and mutate length to weight before summarizing by weight for each haul:

```{r, message = FALSE}
by.haul.positive <- 
  hl %>% 
  select(-sex) %>% 
  filter(latin == Latin) %>% 
  drop_na() %>% 
  # additional code
  mutate(wt = n * 0.00001 * length^3) %>% 
  group_by(id) %>% 
  summarise(n = sum(n),
            # additional code
            wt = sum(wt))

by.haul <-
  hh %>% 
  select(id, year, quarter, haulval) %>% 
  left_join(by.haul.positive) %>% 
  mutate(n  = replace_na(n,  0),
         # additional code
         wt = replace_na(wt, 0))
by.haul %>% 
  filter(haulval == "V") %>% 
  mutate(year = year + 0.25 * quarter - 0.125) %>% 
  # Note: Here only replaced variable "n" with "wt":
  ggplot(aes(year, wt, colour = factor(quarter))) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.1) +
  expand_limits(y = 0) +
  scale_color_brewer(palette = "Set1") +
  labs(x = NULL, y = NULL,
       colour = "Quarter",
       title = paste("Mean catch [kg] of", Latin, "per 1 hour haul"),
       subtitle = "Bootstrap mean and one standard error")
```

The above code could easily be amended if one were interested in exploring the trend for lets say only the larger sized fish (only one line needs to be added). We will however go into more details on that in the next subsection.

### More species

With some yet another minor tweaking we can actually do this for all species. Here we will though limit ourselves to some "common" species:

```{r}
Latin <- c("Clupea harengus", "Sprattus sprattus", "Gadus morhua",
           "Melanogrammus aeglefinus", "Merlangius merlangus", "Pollachius virens",
           "Trisopterus esmarkii", "Scomber scombrus", "Pleuronectes platessa",
           "Solea solea", "Anarhichas lupus", "Lophius piscatorius")

by.haul.positive <- 
  hl %>% 
  select(-sex) %>% 
  filter(latin %in% Latin) %>% 
  drop_na() %>% 
  mutate(wt = n * 0.00001 * length^3) %>% 
  # additional code: added latin to the grouping
  group_by(id, latin) %>% 
  summarise(n = sum(n),
            wt = sum(wt))
```

Now, since we have more than one species the following **will not work** for us (see [on missingness](#onmissingness) in the Auxiliary chapter, explaining why with some simplified haul and count dataframes as examples):

```{r, eval = FALSE}
# Not run
by.haul <-
  hh %>% 
  select(id, year, quarter, haulval) %>% 
  left_join(by.haul.positive) %>% 
  mutate(n  = replace_na(n,  0),
         wt = replace_na(wt, 0))
```

The simplest way to include implicitly missing species is to first generate a dataframe that contains all the hauls and species combination before one does the left join with the count data. Here we use the function crossing (again see [on missingness](#onmissingness)):
```{r message = FALSE}
all <- 
  hh %>% 
  filter(haulval == "V") %>% 
  # Lets only carry forward variables "needed"
  select(id, year, quarter, shootlong, shootlat, faoarea) %>% 
  crossing(latin = Latin)
by.haul <- 
  all %>% 
  left_join(by.haul.positive) %>% 
  mutate(n = replace_na(n, 0),
         wt = replace_na(wt, 0))
glimpse(by.haul)
```

Now the number of records in the "all" dataframe is `r nrow(all)`. This is equivalent to the number of valid hauls in the "hh" dataframe (`r hh %>% filter(haulval == "V") %>% nrow()` records) times the number of species we chose to work with (`r length(Latin)` species). Take also note, that the "by.haul" dataframe has the same number of records - so the left-join does not really add more records, just adds the abundance and the weight variables to the proper haul and species variable combination.

So we are now able to calculate and plot the bootstrap means and standard error:
```{r}
by.haul %>% 
  mutate(year = year + 0.25 * quarter - 0.125) %>% 
  ggplot(aes(year, wt, colour = factor(quarter))) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.1) +
  expand_limits(y = 0) +
  scale_color_brewer(palette = "Set1") +
  labs(x = NULL, y = NULL,
       colour = "Quarter",
       title = "Mean catch [kg] per 1 hour haul",
       subtitle = "Bootstrap mean and one standard error") +
  facet_wrap(~ latin, scale = "free_y")
```

```{r echo = FALSE, eval = FALSE}
# Since we are at it, and since we have included some additional variables we could "look" at the 
by.haul %>% 
  filter(latin == "Gadus morhua",
         quarter == 3) %>% 
  mutate(year = year + 0.25 * quarter - 0.125) %>% 
  ggplot(aes(year, wt)) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.1) +
  expand_limits(y = 0) +
  scale_color_brewer(palette = "Set1") +
  labs(x = NULL, y = NULL,
       title = "Mean catch [kg] per 1 hour haul",
       subtitle = "Bootstrap mean and one standard error") +
  facet_wrap(~ faoarea, scale = "free_y")
by.haul %>% 
  filter(latin == "Gadus morhua",
         quarter == 3,
         str_sub(faoarea, 1, 4) %in% "27.4") %>%
  mutate(lat = round(shootlat),
         year = year + 0.25 * quarter - 0.125) %>% 
  ggplot(aes(year, wt)) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.1) +
  expand_limits(y = 0) +
  scale_color_brewer(palette = "Set1") +
  labs(x = NULL, y = NULL,
       title = "Mean catch [kg] per 1 hour haul",
       subtitle = "Bootstrap mean and one standard error") +
  facet_grid(faoarea ~ ., scale = "free_y")
```

### Spatial distribution

Just because we can, it is easy to plot a spatial distribution of abundance or biomass from the above data. E.g. to plot the distribution of catch by species in the most recent survey all that is needed is:
```{r, message = FALSE}
m <- map_data("world", xlim = range(by.haul$shootlong), ylim = range(by.haul$shootlat))
by.haul %>% 
  filter(year == 2018,
         quarter == 1) %>% 
  ggplot() +
  geom_polygon(data = m, aes(long, lat, group = group), fill = "grey") +
  geom_point(aes(shootlong, shootlat, size = wt), colour = "red", alpha = 0.5) +
  scale_size_area(max_size = 10) +
  scale_x_continuous(NULL, NULL) +
  scale_y_continuous(NULL, NULL) +
  coord_quickmap(xlim = range(by.haul$shootlong), ylim = range(by.haul$shootlat)) +
  facet_wrap(~ latin,
             nrow = 2) +
  labs(size = "kg hr-1",
       title = "Catch per standardized haul",
       subtitle = "NS-IBTS 2018, quarter 1")
```

Or one could select one species and plot different years:

```{r}
Latin <- "Anarhichas lupus"
by.haul %>% 
  filter(year %in% 2010:2018,
         latin == Latin) %>% 
  ggplot() +
  geom_polygon(data = m, aes(long, lat, group = group), fill = "grey") +
  geom_point(aes(shootlong, shootlat, size = wt), colour = "red", alpha = 0.5) +
  scale_size_area(max_size = 10) +
  scale_x_continuous(NULL, NULL) +
  scale_y_continuous(NULL, NULL) +
  coord_quickmap(xlim = range(by.haul$shootlong), ylim = range(by.haul$shootlat)) +
  facet_grid(quarter ~ year) +
  labs(size = "kg hr-1",
       title = paste0(Latin, ": Catch per standardized haul"),
       subtitle = "NS-IBTS quarter 1 and 3")
```

Similarly as one rasterized temperature in the haul chapter we could rasterize the biomass by say statistical rectangles and plot it according to:
```{r, fig.height = 8}
by.square <-
  by.haul %>% 
  mutate(long = gisland::grade(shootlong, 1),
         lat  = gisland::grade(shootlat, 0.5)) %>% 
  group_by(year, quarter, latin, long, lat) %>% 
  summarise(n = mean(n),
            wt = mean(wt))
Latin <- "Pleuronectes platessa"
by.square %>% 
  filter(latin == Latin,
         quarter == 1,
         year >= 1975) %>% 
  mutate(wt = ifelse(wt > quantile(wt, 0.50), quantile(wt, 0.50), wt),
         # for zero squares - plot as grey
         wt = ifelse(wt == 0, NA_real_, wt)) %>% 
  ggplot(aes(long, lat)) +
  geom_raster(aes(fill = wt)) +
  scale_fill_viridis_c(option = "B", direction = -1) +
  geom_polygon(data = m, aes(group = group), fill = "grey") +
  coord_quickmap(xlim = range(hh$shootlong), ylim = range(hh$shootlat)) +
  facet_wrap(~ year) +
  scale_x_continuous(NULL, NULL) +
  scale_y_continuous(NULL, NULL) +
  labs(fill = "kg hr-1",
       title = paste0(Latin, ": Mean catch per square"),
       subtitle = "NS-IBTS, quarter 1")
```

NOTE: Must say that for the historical part the zero catch squares (for plaice) are a bit intriguing - is it a bug in the code, the way things were recorded in different cruises or a reflection of biological truth?

## CPUE per length per haul
___

In section above we started off by collapsing all size structured information. However, we are often interested in exploring and using the more detailed measurements by length. Lets start by looking at only one species

```{r}
Latin <- "Pleuronectes platessa"

by.haul.positive <- 
  hl %>% 
  filter(latin == Latin) %>% 
  # Ignore sex, but tally up numbers by length
  group_by(id, latin, length) %>% 
  summarise(n = sum(n)) %>% 
  ungroup() %>% 
  drop_na()
```

Lets take some two random station and look at the data by length:
```{r}
set.seed(31)
IDS <-
  hh %>% 
  filter(year == 2018, 
         id %in% unique(by.haul.positive$id)) %>% 
  sample_n(2) %>% 
  pull(id)
by.haul.positive %>% 
  filter(id %in% IDS) %>% 
  select(id, length, n) %>% 
  spread(id, n) %>% 
  knitr::kable()
```

We observe that the fish reported in different haul do not "cover" the same length classes. Now although this is expected, when summarizing the data we need to take this into account. The "missingness" means implicitly that the value are effectively zero.

We also observe that we have a mixture of measurements, some (likely) only measuring the fish to the nearest centimeter in other cases to the nearest millimeter. So before proceeding lets "collapse" the length measurements to the nearest centimeter:

```{r}
Latin <- "Pleuronectes platessa"
by.haul.positive <- 
  hl %>% 
  filter(latin == Latin) %>% 
  mutate(length = floor(length)) %>% 
  group_by(id, latin, length) %>% 
  summarise(n = sum(n)) %>% 
  drop_na()
```

Note: The value of the length variable is to be understood as the lower boundary of a 1 centimeter bin. I.e. a length value of 10 represents a fish between 10-10.99... centimeters. 

To take into account the "missingness" we could take the same approach as when we were coding for more than one species, i.e. we generate a full matrix of lengths at each station.

```{r}
all <- 
  hh %>% 
  filter(haulval == "V") %>% 
  # Lets only carry forward variables "needed"
  select(id, year, quarter, shootlong, shootlat, faoarea) %>% 
  crossing(length = sort(unique(by.haul.positive$length)),
           latin = unique(by.haul.positive$latin))
```

So we started with a haul dataframe with `r hh %>% filter(haulval == "V") %>% nrow()` observations and ending up with the "all" dataframe of some `r nrow(all)` records. This is a result of the unique length classes for the selected species being `r length(unique(by.haul.positive$length))`.

NOTE: May actually want to code length above a sequence of from min to max lengths stepping by each length bin, because here we may have missing lengths bins somewhere "inbetween".

We now merge the dataframes so that we have a "complete matrix" of length, latin and number of fish for each haul:
```{r}
by.haul <- 
  all %>% 
  left_join(by.haul.positive, by = c("id", "length", "latin")) %>% 
  mutate(n = replace_na(n, 0),
         wt = n * 0.00001 * (length + 0.5)^3)
```

Lets now look at the two hauls we peeked at earlier (Table xxx):

```{r}
by.haul %>% 
  filter(id %in% IDS) %>% 
  select(id, length, n) %>% 
  spread(id, n) %>% 
  knitr::kable()
```

We have now a complete record for all lengths classes reported in the survey and for each of the length class we have the number of observations including zero counts. This includes hauls were no fish for a particular species was measured. As an example:

```{r}
by.haul %>% 
  filter(id == "2018_1_58G2_GOV_10") %>% 
  select(id, length, n) %>% 
  knitr::kable()
```

Hence any statistical analysis done based on this data structure becomes consquently simple.

We can now calculate the mean catch per length class per year:
```{r}
cpue <- 
  by.haul %>% 
  group_by(year, quarter, length) %>% 
  summarise(hauls = n(),
            n = mean(n),
            wt = mean(wt))
```

and create a plot
```{r, fig.height = 9}
cpue %>% 
  filter(year >= 2004) %>% 
  ggplot(aes(length, wt, colour = factor(quarter))) +
  geom_line() +
  scale_color_brewer(palette = "Set1") +
  facet_grid(year ~ .) +
  labs(x = "Length [cm]",
       y = "Mean number of fish",
       colour = "Quarter",
       title = paste0(Latin, ": Mean number of fish per 1 hour"))
```

Take note that we can easily repeat the calculation of catch-per-unit-effort by year as done in the first subsection above using the "by.haul" dataframe that does not have any "missingness" created in this subsection (not run):
```{r, eval = FALSE}
by.haul %>% 
  group_by(id, year, quarter, latin) %>% 
  summarise(n = sum(n),
            wt = sum(wt)) %>% 
  ungroup() %>% 
  mutate(year = year + 0.25 * quarter - 0.125) %>% 
  ggplot(aes(year, wt, colour = factor(quarter))) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.1) +
  expand_limits(y = 0) +
  scale_color_brewer(palette = "Set1") +
  labs(x = NULL, y = NULL,
       colour = "Quarter",
       title = "Mean catch [kg] per 1 hour haul",
       subtitle = "Bootstrap mean and one standard error") +
  facet_wrap(~ latin, scale = "free_y")
```

### A little convenient function

In the above we got a little appreciation for not forgetting to take into account "missingness" in the DATRAS dataframes. It basically mean a little bit of extra coding where we both have to take the haul data and the length data into consideration. Since we may be doing this quite frequently a little convenient function, that encapsulates the above code may be in order:

```{r, eval = FALSE}
cpue_per_length_per_haul <- function(hh, hl, Latin) {
  
  by.haul.positive <- 
    hl %>% 
    filter(latin == Latin) %>% 
    mutate(length = floor(length)) %>% 
    # Note: we are collapsing sex and maturity
    group_by(id, latin, length) %>% 
    summarise(n = sum(n)) %>% 
    drop_na()
  
  all <- 
    hh %>% 
    filter(haulval == "V") %>% 
    # Lets only carry forward variables "needed"
    select(id, year, quarter) %>% 
    crossing(length = sort(unique(by.haul.positive$length)),
             latin = unique(by.haul.positive$latin))
  
  by.haul <- 
    all %>% 
    left_join(by.haul.positive) %>% 
    mutate(n = replace_na(n, 0))
  
  return(by.haul)
  
}
```

This code is available in the R/00_main.R script and we can source it (and other functions that may reside in the file) by:
```{r}
source("R/00_main.R")
```

For any species we can now just do:

```{r, fig.height = 9}
Latin <- "Solea solea"
d <-
  cpue_per_length_per_haul(hh, hl, Latin)

d %>% 
  group_by(year, quarter, length) %>% 
  summarise(hauls = n(),
            n = mean(n)) %>% 
  filter(year %in% 1994:2018,
         quarter == 1) %>% 
  ggplot(aes(length, n)) +
  geom_line() +
  facet_wrap(~ year) +
  labs(x = "Length [cm]",
       y = "Mean number of fish",
       colour = "Quarter",
       title = paste0(Latin, ": Mean number of fish per 1 hour"))
```

... or even a little bootstrap on abundance by length :-)
```{r}
d %>% 
  filter(year %in% 2018,
         quarter == 1) %>% 
  ggplot(aes(length, n)) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.1)
```

## Emulating DATRAS service product

NOTE: Some intro notes here ...

```{r}
common <- c("Clupea harengus", "Sprattus sprattus", "Gadus morhua",
            "Melanogrammus aeglefinus", "Merlangius merlangus", "Pollachius virens",
            "Trisopterus esmarkii", "Scomber scombrus", "Pleuronectes platessa")
cpue <- 
  # only valid hauls
  # Note: This is an inbuild function - not exactly the same as above
  tidyices::cpue_per_length_per_haul(hh = hh %>% filter(haulval == "V", !is.na(nsarea)),
                           hl = hl) %>% 
  filter(latin %in% common) %>% 
  # debugging, this should be fixed upstream
  filter(!is.na(length))
```

```{r}
# comparision with the datras-product
Latin <- "Pleuronectes platessa"
d1 <- 
  cpue %>% 
  id_separate(remove = FALSE) %>% 
  filter(latin == Latin,
         year == 2016,
         quarter == 1) %>% 
  select(id, latin, length, n) %>% 
  mutate(length = as.integer(length * 10),
         source = "tidy") %>% 
  arrange(id, length, n)
fi <- 
  "data-raw/CPUE per length per haul per hour_2018-06-30 15_34_50.csv"
d2 <-
  read_csv(fi, na = "-9") %>% 
  rename_all(tolower) %>% 
  filter(species == Latin,
         year == 2016,
         quarter == 1) %>% 
  id_unite() %>% 
  select(id, 
         latin = species, 
         length = lngtclass, 
         n = cpue_number_per_hour) %>% 
  as_tibble() %>% 
  mutate(source = "datras") %>% 
  arrange(id, length, n)
d1 %>% 
  bind_rows(d2) %>% 
  spread(source, n) %>% 
  mutate(diff = !near(tidy, datras, tol = 1e-4)) %>% 
  filter(diff) 
```




```{r, message = FALSE, warning = FALSE}
cpue2 <-
  cpue %>%
  id_separate(remove = FALSE) %>%
  filter(year %in% 2005:2016) %>% 
  select(id, latin, length, cpue.tidy = n) %>% 
  mutate(length = as.integer(length * 10))
fi <- 
  "data-raw/CPUE per length per haul per hour_2018-06-30 15_34_50.csv"
cpue.datras.service.product <-
  read_csv(fi, na = "-9") %>% 
  rename_all(tolower)
cpue.datras.service.product <-
  cpue.datras.service.product %>%
  filter(year %in% 2005:2016) %>% 
  id_unite() %>% 
  select(id, latin = species, length = lngtclass, cpue.dsp = cpue_number_per_hour) %>% 
  as_tibble()

diff <-
  cpue2 %>% 
  full_join(cpue.datras.service.product) %>%
  mutate(diff = !near(cpue.dsp, cpue.tidy, tol = 1e-4),
         txt = ifelse(!diff, "Same",
                      ifelse(diff, "Difference", "One of the value is NA")))
diff %>% 
  group_by(txt) %>% 
  summarise(n.records = n()) %>% 
  knitr::kable()
```

We have 515584 records that are OK and then 953 records that are different. We have 1642 values that are "NA" meaning that either of the cpue or both were missing.

```{r}
x <- diff %>% filter(is.na(txt))
table(!is.na(x$cpue.tidy), !is.na(x$cpue.dsp))
```

So have 1374 observations that are in "tidy" but not in "dsp" and 268 observations in "dsp" that are not in "tidy"

**Lets print the 268 observations that are not in "tidy"**:

```{r}
diff %>% 
  filter(is.na(txt), !is.na(cpue.dsp)) %>% 
  arrange(latin) %>% 
  knitr::kable()
```

What is the story with the single haddock?:
```{r}
raw <- read_rds("data-raw/datras/ns-ibts_raw.rds")
hl_raw <-
  raw$hl %>% 
  rename_all(tolower)
hl_raw %>% 
  as_tibble() %>% 
  id_unite() %>% 
  filter(id == "2009_1_THA2_GOV_26",
         valid_aphia == 126437) %>% glimpse()
```

So, it does not appear in the hl_raw dataframe. And because these are all of `lngtcode == "0"` these fish are what is termed as 0.5 cm length class, reporting units of millimeter. For the time being this does not quite make sense in my head.

What do we have in tidy for the haul and species in question?:
```{r}
cpue2 %>% 
  filter(id == "2009_1_THA2_GOV_26",
         latin == "Melanogrammus aeglefinus") %>% glimpse()
```

So no 20 cm fish

And in the dsp:
```{r}
cpue.datras.service.product %>% 
  filter(id == "2009_1_THA2_GOV_26",
         latin == "Melanogrammus aeglefinus") %>% glimpse()
```

We have only 20, 30 and 40 cm fish. So it seems like in the dsp the length class are treated as millimeters that are then converted to centimeters by rounding.


## Field names
___

* **StNo**: National coding system, not defined by ICES
* **HaulNo**: Sequential numbering of hauls during cruise. In CA-records: HaulNo = -9 for Area-based ALK HaulNo <> -9 and > 0 for Haul-based ALK
* **DataType**:
    - -9: Invalid haul
    - C: Data calculated as CPUE (number per hour)
    - R: Data by haul
    - S: Subsample data
* **SpecCodeType**:
    - N: NODC code
    - T: TSN code
    - W: WoRMS ApiaID code
* **LngtCode**:
    - .:	1 mm length class, reporting units: mm
    - 0:	0.5 cm length class, reporting units: mm
    - 1:	1 cm length class, reporting units: cm
* **CatIdentifier**: Category for subsampling for species, length, weight, and sex. If **DataType** is C, **CatIdentifier** is always 1. For further description and examples of use look up the manual.
* **SubFactor**: Sub-sampling factor. If 1/6 of the catch was measured, report 6. If **DataType** is:
    - C: it should be reported as 1. 
    - S: it is always >1.
    - R: the SubFactor is = 1 or >1 for different species depending on whether they were subsampled.
