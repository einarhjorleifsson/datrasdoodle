# Age based indices {#alk}

```{r, warning = FALSE, message = FALSE}
library(tidyverse)
library(lubridate)
library(patchwork)
theme_set(theme_grey())
```

```{r}
hh <- read_rds("data/ns-ibts_hh.rds")
hl <- read_rds("data/ns-ibts_hl.rds")
ca <- read_rds("data/ns-ibts_ca.rds")
```

NOTE: Need to check interpretation of the n-variable (original name CANoAtLngt) in ca-data. The [DATRAS pages](https://datras.ices.dk/Data_products/FieldDescription.aspx?Fields=CANoAtLngt&SurveyID=2341) refer to this variable as meaning: "Amount of fish at the given category (per haul, species, length class, sex, maturity, age)."


## Converting length to age

### The principle - empirical approach

Length data are relatively cheap to record relative to age data, because for the latter one needs to read annual rings from hard structure (normally otoliths) which require often laborious preparatory work in addition to counting rings. Hence in surveys the length measurements are more numerous, the objective being to estimate with good accuracy the length distribution of the catch at each station while otoliths are only collected from a smaller subsample of the catch.

The sub-samples of the age data is then used to calculate the probability of age for a given length class, generally called an age-length key (alk). This data is then used to split the length data into age classes.

Lets summarize some length frequency and age-length data for one species in one survey:

```{r}
Latin <- "Gadus morhua"
lfs <-
  hh %>% 
  filter(year == 2014,
         quarter == 3) %>% 
  select(id) %>% 
  left_join(hl, by = "id") %>% 
  filter(latin == Latin) %>% 
  mutate(length = floor(length)) %>% 
  group_by(length) %>% 
  summarise(n = sum(n, na.rm = TRUE)) %>% 
  drop_na()

p1 <-
  lfs %>% 
  ggplot(aes(length, n)) +
  theme_grey() +
  geom_col() +
  labs(x = NULL,
       subtitle = "Length frequency")

alk.empirical <-
  hh %>% 
  filter(year == 2014,
         quarter == 3) %>% 
  select(id) %>% 
  left_join(ca, by = "id") %>% 
  filter(latin == Latin) %>% 
  mutate(length = floor(length),
         age = ifelse(age > 9, 9, age)) %>% 
  group_by(age, length) %>% 
  summarise(n = sum(n)) %>% 
  group_by(length) %>% 
  mutate(p = n / sum(n, na.rm = TRUE)) %>% 
  select(-n) %>% 
  drop_na()
p2 <-
  alk.empirical %>% 
  mutate(age = ifelse(age > 9, 9, age)) %>% 
  ggplot(aes(length, p, fill = factor(age))) +
  theme_grey() +
  scale_fill_brewer(palette = "Set3") +
  geom_col() +
  labs(x = "Length",
       y = "Proportion",
       fill = "Age",
       subtitle = "Proportion of age at length")

p1 + p2 + plot_layout(ncol = 1)
```


In principle we want to split the each length class of the length distribution (top graph) into separate age groups based on the age-length key (lower graph). Visually this may be easy for the first mode, almost all fish in each length class belonging to age group 0. Beyond that, each length class is most often composed of more than one age groups. 

Lets look at the alk for the 70 cm length class:
```{r}
alk.empirical %>% 
  filter(length == 70) %>% 
  knitr::kable()
```

Here we have 5 age-classes in the length class, the most numerous ones being age 3 (50%), then 4 (22%) and 5 (17%), while around 6% of the fish are of age 2 and 6.

We use this probability to split each length class into ages. Here we simply have to join joining the length-frequency and the alk dataframes and split the count tally (n) in each length group into number of fish at each age (n.nage) by multiply the number measured by length with the probability:

```{r}
d <- 
  lfs %>% 
  left_join(alk.empirical, by = "length") %>% 
  mutate(n.age = p * n)
```

If we check the 70 cm length class again we now have an estimate of the number of fish by each age-class:
```{r}
d %>% 
  filter(length == 70) %>% 
  knitr::kable()
```

Visually we have now the following:

```{r}
d %>% 
  ggplot(aes(length, n.age, fill = factor(age))) +
  theme_grey() +
  geom_col() +
  scale_fill_brewer(palette = "Set3") +
  labs(x = "Length",
       y = "n",
       fill = "Age",
       subtitle = "Length frequency by age")
```

We can now also look at the age distribution:
```{r}
indices.alk.empirical <- 
  d %>% 
  group_by(age) %>% 
  summarise(n.age = sum(n.age, na.rm = TRUE)) %>% 
  drop_na()
indices.alk.empirical %>% 
  ggplot(aes(age, n.age)) +
  geom_col() +
  scale_x_continuous(breaks = 0:10) +
  labs(x = "Age",
       y = "n")
```

### Statistical modelling

```
NOTE: Some of the stuff here should be moved into the subection above.
```

In the above empirical approach there is a bit of a problem  - missingness :-)  The reader may have noticed the warning message given when plotting the "Length frequency by age":
```
## Warning: Removed 1 rows containing missing values (position_stack).
```
This message was given because varible n.age has one record with NA. It so happens that it is the first record so we can see it by:
```{r}
glimpse(d)
```

This means that length class 5 cm was recorded in the length measurements (hl), but no fish of that length class was aged (ca) in the year (2014) and quarter (3) for the species (Gadus morhua) in question. Since in this particular case it was the smallest length class one could obviously assign it "manually" to the youngest age group (age 0) in the dataset. But "missingness" of age samples in other length classes are bound to occur, particularly if we start to use some kind of spatial stratification of the age-length-key. So we need some generic approach. In this subsection we will take take some statistical approach.

**JUST A PLACEHOLDER FOR NOW**
```{r}
# NOTE: Function will be put into a packages in the end
cpue_per_length_per_haul <- function(hh, hl, Latin) {
  
  by.haul.positive <- 
    hl %>% 
    filter(latin == Latin) %>% 
    mutate(length = floor(length)) %>% 
    # Note: we are collapsing sex and maturity
    group_by(id, latin, length) %>% 
    summarise(n = sum(n)) %>% 
    drop_na()
  
  all <- 
    hh %>% 
    filter(haulval == "V") %>% 
    # Lets only carry forward variables "needed"
    select(id, year, quarter) %>% 
    crossing(length = sort(unique(by.haul.positive$length)),
             latin = unique(by.haul.positive$latin))
  
  by.haul <- 
    all %>% 
    left_join(by.haul.positive) %>% 
    mutate(n = replace_na(n, 0))
  
  return(by.haul)
  
}
```

```{r}
Latin <- "Gadus morhua"
lfs <-
  cpue_per_length_per_haul(hh, hl, Latin)

lfs <-
  lfs %>% 
  filter(year == 2014,
         quarter == 3) %>% 
  group_by(length) %>% 
  summarise(n = sum(n, na.rm = TRUE))

alk.empirical <-
  hh %>% 
  filter(year == 2014,
         quarter == 3) %>% 
  select(id) %>% 
  left_join(ca, by = "id") %>% 
  filter(latin == Latin) %>% 
  mutate(length = floor(length),
         age = ifelse(age > 9, 9, age)) %>% 
  group_by(age, length) %>% 
  # NOTE: : Need to check interpetation of the n-variable in ca-data
  summarise(n = sum(n)) %>% 
  group_by(length) %>% 
  mutate(p = n / sum(n, na.rm = TRUE)) %>% 
  select(-n) %>% 
  drop_na()
```

Lets make a visual peek:
```{r}
alk.empirical %>% 
  ggplot(aes(length, p, colour = factor(age))) +
  geom_point() +
  geom_line(lwd = 0.3, linetype = 5) +
  scale_color_brewer(palette = "Set3")
```

#### The mlogit model

....

Reference to @henningsen2011maxlik

```{r}
# library(mlogit)
alk.mldata <-
  hh %>% 
  filter(year == 2014,
         quarter == 3) %>% 
  select(id) %>% 
  left_join(ca, by = "id") %>% 
  filter(latin == Latin) %>% 
  mutate(length = floor(length)) %>% 
  select(lngtclass = length,
         age,
         n) %>% 
  # NOTE: Need to check interpetation of the n-variable in ca-data
  uncount(n) %>% 
  mlogit::mlogit.data(varying = NULL, choice = 'age', shape = 'wide')
m <- mlogit::mlogit(age~1 | lngtclass, data = alk.mldata, reflevel = "1")

tidy_mlogit <- function(m, lengths = 1:200, ages = 0:10) {
  
  x <- coefficients(m)
  
  p <-
    data_frame(variable = names(x),
                  value = x) %>% 
    separate(variable, c("age", "parameter"), sep = ":", convert = TRUE) %>% 
    mutate(parameter = str_replace(parameter, "\\(", ""),
           parameter = str_replace(parameter, "\\)", "")) %>% 
    spread(parameter, value)
  
  d <- 
    crossing(age = ages,
             length = lengths) %>% 
    left_join(p, by = "age") %>% 
    mutate(intercept = replace_na(intercept, 0),
           lngtclass = replace_na(lngtclass, 0),
           p = exp(intercept + lngtclass * length)) %>% 
    # Probabilities of all ages within a length class
    #   must sum to one
    group_by(length) %>% 
    mutate(p = p / sum(p)) %>% 
    ungroup() %>% 
    select(age, length, p)
  
  return(d)

}
alk.model <- 
  m %>% 
  tidy_mlogit(lengths = c(min(lfs$length):max(lfs$length)),
              ages = c(0:10))
              #ages =    c(min(alk.raw$age):max(alk.raw$age)))
```

```{r}
alk.model %>% glimpse()
alk.model %>% filter(length == min(length)) %>% glimpse()
```

So even in the smallest length class (1 cm) we have some small probabilities that the fish will belong to some older age classes. Although biologically not really possible, that is statistics :-) The beauty is though that know we have solved the problem of "missingness" in our data - all length classes will be assigned to having some probabilities of belonging to all of the age classes in the data. Before we proceed, lets take a visual peek of what we have just done:

```{r}
alk.model %>% 
  ggplot(aes(length, p, colour = factor(age))) +
  geom_line() +
  scale_colour_brewer(palette = "Set3")
```

Let's make a comparison between this model and the empirical observations:

```{r}
ggplot() +
  geom_point(data = alk.empirical,
            aes(length, p, colour = factor(age))) +
  geom_line(data = alk.empirical,
            aes(length, p, colour = factor(age)),
            lwd = 0.3, linetype = 5) +
  geom_line(data = alk.model,
            aes(length, p, colour = factor(age))) +
  scale_colour_brewer(palette = "Set3") +
  labs(x = "Length [cm]",
       y = "Probability",
       colour = "Age",
       title = "Probability of age by length",
       subtitle = "Empirical (points and dashed line) and mlogit fit (line)")
```

We can now use the modelled alk's to the length frequency distribution:

```{r}
indices.alk.model <- 
  lfs %>% 
  left_join(alk.model, by = "length") %>% 
  mutate(n.age = p * n) %>% 
  group_by(age) %>% 
  summarise(n.age = sum(n.age))
```

```{r}
indices.alk.model %>% 
  ggplot(aes(age, n.age)) +
  geom_col() +
  scale_x_continuous(breaks = 0:10) +
  labs(x = "Age",
       y = "n")
```

Whats the difference between using an empirical vs a modeled alk?:

```{r}
d <- 
  indices.alk.empirical %>% 
  mutate(alk = "empirical") %>% 
  bind_rows(indices.alk.model %>% 
              mutate(alk = "model"))
p <-
  d %>% 
  ggplot(aes(age, n.age, fill = alk)) +
  geom_col(position = "dodge") +
  scale_fill_brewer(palette = "Set1") +
  scale_x_continuous(breaks = 0:10) +
  labs(x = "Age",
       y = "n") +
  theme(legend.position = c(0.8, 0.65))
p
```

On an ordinary scale the difference in not visible, however on a log-scale we have:
```{r}
p +
  scale_y_log10()
```

Here there is a slight difference in the oldest age groups where we have relatively few data. In some cases this may matter because the total mortality signal (the slope) is based on log of the index.

#### Some other statistical model

... check @berg2012spatial



### The engineer's approach

...

## Age based indices
