--- 
title: "Playing with Datras data"
author: "Einar Hj√∂rleifsson"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output:
  bookdown::gitbook:
    fig_height: 6
    fig_width: 9
documentclass: book
bibliography: [ddoodle.bib]
biblio-style: apalike
link-citations: yes
github-repo: einarhjorleifsson/datrasdoodle
description: "Better find some dam description ..."
---

# Preamble {-}

```{r, echo = FALSE, out.width='100%'}
knitr::include_graphics("img/gagnakvorn.png")
```

The process that leads to advice involves multiple steps both on data munging and (ab)use of models. The process from raw data to advice can in many cases be described as a low-pass filter being passed to another low-pass filter passed on to yet another low-pass filter. During these steps the information in the raw data is sometimes lost. Making inference/explaining how an advice relates to the raw data quite often difficult, if not impossible.

The scribble that follows contains snapshots/examples of tidyverse code used for data exploration analysis of the DATRAS dataset, (groundfish) survey data that is one of the two pillars of data sources (the other being commercial catch-at-age) that forms the corner of most advice based on analytical models.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(gisland)
d <-
  read_rds("data/hh_datras.rds") %>% 
  filter(year == 2017)

icesarea <- 
  gisland::read_sf_ftp("fao-areas") %>%
  mutate(reg = str_sub(name, 1, 2)) %>%
  # only ICES areas
  filter(reg == "27") %>% 
  # turn the sf-object into sp-object so it can be used by calling geom_path
  as("Spatial")

d %>% 
  ggplot() +
  theme_void() +
  geom_polygon(data = map_data("world"), aes(long, lat, group = group), fill = "grey") +
  geom_path(data = icesarea, aes(long, lat, group = group), colour = "grey") +
  geom_point(aes(shootlong, shootlat, colour = survey),
             size = 0.5) +
  coord_quickmap(xlim = range(d$shootlong), ylim = range(d$shootlat)) +
  labs(colour = "Survey")
```

The scribbles provided here are not to be considered as teaching the basics of the tidyverse coding framework, for that read [R for data science](http://r4ds.had.co.nz/) by @wickham2016r.

At present, the scribbles are a total mess, the space just some ad-hoc codes exploring the DATRAS data. The thinking/hope is that the space will ultimately become guidelines/templates/example codes on exploring, visualizing and utilizing the vast resource that the DATRAS data truly is.

The aim is that the text as well as the R-code snippets should of course be human readable (a task that has been made more easy with the advent of the tidyverse sweep of packages) and fully reproducible (from a to z). Any additional functions beyond those currently available in the tidyverse dialect should be kept to an absolute minimum (tidy codes are all alike but every messy code is messy in its own way). But those added should be explained in detail.

